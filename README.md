# RAG Challenge

RAG-соревнование, в котором нужно найти ответы на вопросы, используя предоставленный корпус документов.

## Разделение на тренировочную и валидационную часть

- Сейчас доступен тренировочный датасет (`questions_data`, `docs_metadata.json`, `questions.jsonl`) и бейзлайн-скрипт (`baseline.ipynb`) в папке `train`
- На паре **20.12** будет предоставлен новый датасет в том же формате, но с меньшим количеством вопросов

## Структура репозитория

```
train/
├── baseline.ipynb      # Пример RAG-системы с оценкой качества
├── questions.jsonl     # Вопросы (по одному JSON-объекту на строку)
├── docs_metadata.json  # Метаданные документов (время редактирования)
└── questions_data/     # Папка с HTML-документами (0.html, 1.html, ...), нужно скачивать отдельно
```

### Скачивание данных

[Скачать архив с документами (questions_data.zip)](https://huggingface.co/datasets/Fourzeroo/ITMO-LLM-Course-RAG/resolve/main/questions_data.zip?download=true)

Также можно скачать архив напрямую из ноутбука (см. `baseline.ipynb`).

## Формат данных

### questions.jsonl

Каждая строка — JSON-объект с полями:

| Поле | Описание |
|------|----------|
| `query` | Текст вопроса |
| `query_time` | Время вопроса (может быть важно для вопросов про актуальные данные) |
| `domain` | Тематика вопроса (sports, music, ...) |
| `question_type` | Тип вопроса (см. ниже) *(только в train)* |
| `answer` | Правильный ответ *(только в train)* |
| `alt_ans` | Альтернативные правильные ответы *(только в train)* |
| `documents` | Список релевантных документов *(только в train)* |

### docs_metadata.json

Словарь вида `{"filename": {"page_last_modified": "..."}}` — содержит время последнего редактирования страницы. Может пригодиться для вопросов, связанных со временем.

### questions_data/

Папка с документами. Большинство документов содержит HTML-разметку — рекомендуется предварительная очистка.

Не все документы могут быть в формате HTML. Еще один возможный формат - `.txt` (HTML-разметки там не будет, только текст).

## Типы вопросов

| Тип | Описание |
|-----|----------|
| `simple` | Простой вопрос с однозначным ответом |
| `simple_w_condition` | Простой вопрос с условиями (например, цена в определенную дату) |
| `set` | Ответ — список сущностей |
| `multi-hop` | Требуется несколько шагов поиска информации |
| `false_premise` | Вопрос некорректен, правильный ответ — "Не знаю" / "Вопрос составлен некорректно" |
| `aggregation` | Требуется агрегация данных из разных источников |
| `comparison` | Требуется сравнение сущностей |

> ⚠️ **Важно:** На любой вопрос ответа может не быть в документах. Правильный ответ в таком случае — "Не знаю" или "Не могу ответить".

## Baseline-решение (baseline.ipynb)

Ноутбук содержит пример простой RAG-системы:

1. **Загрузка данных** — чтение вопросов из `questions.jsonl` и документов из `questions_data/`
2. **Чанкинг** — разбиение документов на чанки с помощью `RecursiveCharacterTextSplitter`
3. **Индексирование** — создание FAISS-индекса с эмбеддингами (`all-MiniLM-L6-v2`)
4. **Retrieval** — поиск релевантных чанков по запросу
5. **Generation** — генерация ответа с помощью LLM (Mistral) на основе найденного контекста
6. **Оценка** — LLM-as-a-Judge для оценки качества ответов (только для train-датасета)

> ⚠️ **Важно:** Часть с оценкой (LLM-as-a-Judge) нужна только для тренировочного датасета, на паре она просто не заработает - правильные ответы на вопросы не будут доступны).

*Примечание по LLM-as-a-Judge: в коде используется Mistral API. Если вы будете использовать другого провайдера, например OpenRouter, можно получать ответы на все вопросы из датасета (и на следующей итерации их оценку судьей) одновременно, что сэкономит время на проверку (Mistral API ограничен 1 запросом в секунду и 500 000 токенами в минуту). Для этого нужно немного переработать функцию `evaluate_all_questions`, раскомментировав строки*

### Используемые библиотеки

```
langchain, langchain-mistralai, langchain-community
faiss-cpu
sentence-transformers
mistralai
```

Для получения эмбеддингов также будут нужны:
```
torch
sentence-transformers
datasets
```

Общие пакеты:
```
tqdm
ipykernel
ipywidgets
```

## Формат оценки

Ответы оцениваются метрикой **Truthfulness**:

| Score | Описание |
|-------|----------|
| 1.0 | Полностью верный ответ |
| 0.5 | Частично верный ответ |
| 0.0 | Отказ от ответа (когда ответ есть) |
| -1.0 | Галлюцинация или уверенный неверный ответ |

## Валидационный датасет (20.12)

На паре будут предоставлены новые файлы:
- `questions.jsonl` — новые вопросы (без полей `answer`, `alt_ans`, `documents`, `question_type`)
- `docs_metadata.json` — метаданные новых документов
- `questions_data.zip` — архив с новыми документами

Формат данных останется таким же, поэтому все скрипты, подготовленные на тренировочных данных, будут работать.

## Формат сдачи

- Ответы вводятся в гугл-форму на паре 20.12
- Код решения прикреплять не обязательно
- Выбор инструментов не ограничен
- Объединяться в команды нельзя, ответы могут проверяться на плагиат
